Feature descriptors have always been one of many classical computer vision [techniques](https://docs.opencv.org/3.4/db/d27/tutorial_py_table_of_contents_feature2d.html). In short, feature descriptors are patches of pixels (aka features) that are robust against image transformations (scale, rotation, etc).

However, even the most powerful of the classical computer vision techniques such as SIFT (Scale-invariant Feature Transform) are being outperformed by state-of-the-art deep learning techniques nowadays. This topic piqued the interest of the research department I was in as it introduced a secondary advantage to deep learning.

The company that I work for, LeapMind, primarily focuses on making machine learning available to everyone on edge devices. Deep learning frameworks such as TensorFlow and PyTorch have methods to optimize convolutional networks. In addition, there are many accelerator hardware techniques that may also be applied to speed up inference time. However, since I am mostly a software engineer, our approach to was to design a lightweight feature descriptor which would reduce the computational load enough without sacrificing too much accuracy.

After various surveys of state-of-the-art deep learning feature descriptor techniques, we settled on )[RF-Net](https://arxiv.org/abs/1906.00604) as our target.